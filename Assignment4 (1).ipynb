{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Assignment4.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "9f9d7c1b0a8a417b87313cfab89b3f0d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_35fb5a6893064a188bba3fb7d2e89e50",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_40383165ceb94c9f9eea6974fc0cc770",
              "IPY_MODEL_f2988eadc6ee495f902e460fd3627f4e"
            ]
          }
        },
        "35fb5a6893064a188bba3fb7d2e89e50": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "40383165ceb94c9f9eea6974fc0cc770": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_a0acfb4eb3c943b892b4f1021a9f9434",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 570,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 570,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_7a0ea911a24740ab94211d73c15de3ae"
          }
        },
        "f2988eadc6ee495f902e460fd3627f4e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_e2a7d620398446f0881c165a74c13912",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 570/570 [00:00&lt;00:00, 2.11kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_1b33fa1ac00249548ebb8b2fc8261cbb"
          }
        },
        "a0acfb4eb3c943b892b4f1021a9f9434": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "7a0ea911a24740ab94211d73c15de3ae": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "e2a7d620398446f0881c165a74c13912": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "1b33fa1ac00249548ebb8b2fc8261cbb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "ef23de20ad5144bb955a451047198bc3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_93cb34058a654bd581a2b213519a647a",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_27ec57618b834fefaa7c3b30b472cae4",
              "IPY_MODEL_793cd4450e124cb69ac2ca5458122d81"
            ]
          }
        },
        "93cb34058a654bd581a2b213519a647a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "27ec57618b834fefaa7c3b30b472cae4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_c4ced2fbaf4c4db3a49b2333a0623e07",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 435779157,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 435779157,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_0182f1e5800946b68e50b9bcb481c180"
          }
        },
        "793cd4450e124cb69ac2ca5458122d81": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_bdf7558664324f5eb4a6c48cda4ab37e",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 436M/436M [00:10&lt;00:00, 42.5MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_87be83eb523644d7bfe0c34592019966"
          }
        },
        "c4ced2fbaf4c4db3a49b2333a0623e07": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "0182f1e5800946b68e50b9bcb481c180": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "bdf7558664324f5eb4a6c48cda4ab37e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "87be83eb523644d7bfe0c34592019966": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mu0_8BGBjcf5",
        "outputId": "a3719c98-1ed2-4d36-9fd2-36c060f1b655"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HZjbp5YTjlZD"
      },
      "source": [
        "!pip install -qq transformers"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1ZY2RCuzkcA4"
      },
      "source": [
        "import os\n",
        "import transformers\n",
        "from transformers import BertModel, BertTokenizer, AdamW, get_linear_schedule_with_warmup\n",
        "import torch\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "from pylab import rcParams\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib import rc\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "from collections import defaultdict\n",
        "from textwrap import wrap\n",
        "from torch import nn, optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "%matplotlib inline"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Iv63kbSekm6h"
      },
      "source": [
        "RANDOM_SEED = 42\n",
        "np.random.seed(RANDOM_SEED)\n",
        "torch.manual_seed(RANDOM_SEED)\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4waZzLAgl5BG",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 163
        },
        "outputId": "d7edec33-fb93-49ff-b968-9898c7dd0015"
      },
      "source": [
        "os.chdir('gdrive/MyDrive/CS772')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-39-eaf3c8e1a7ff>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'gdrive/MyDrive/CS772'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'gdrive/MyDrive/CS772'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-amhO99kG-q3",
        "outputId": "eb928507-e356-4e45-bfe1-73d2bf7823a7"
      },
      "source": [
        "!pwd"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/gdrive/My Drive/CS772\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "EMW4UnUSkrYq",
        "outputId": "a36e60f5-a9a9-4c2e-cd06-db75340a16f8"
      },
      "source": [
        "df = pd.read_csv(\"train.csv\")\n",
        "df.drop(\"Unnamed: 0\",axis =1,inplace=True)\n",
        "df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>reviews</th>\n",
              "      <th>ratings</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>This book was very informative, covering all a...</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>I am already a baseball fan and knew a bit abo...</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>I didn't like this product it smudged all unde...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>I simply love the product. I appreciate print ...</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>It goes on very easily and makes my eyes look ...</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                             reviews  ratings\n",
              "0  This book was very informative, covering all a...        4\n",
              "1  I am already a baseball fan and knew a bit abo...        5\n",
              "2  I didn't like this product it smudged all unde...        1\n",
              "3  I simply love the product. I appreciate print ...        5\n",
              "4  It goes on very easily and makes my eyes look ...        5"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        },
        "id": "JmLPK2l2mK-Q",
        "outputId": "4f9ca9fa-3bb2-4d05-83c1-bcf7429a9836"
      },
      "source": [
        "sns.countplot(df.ratings)\n",
        "plt.xlabel('review score');"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pzNr25eOmTSu"
      },
      "source": [
        "PRE_TRAINED_MODEL_NAME = 'bert-base-cased'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xPf7rAc6mZ-O"
      },
      "source": [
        "tokenizer = BertTokenizer.from_pretrained(PRE_TRAINED_MODEL_NAME)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "enO935YRmdP7",
        "outputId": "2c0a97b3-0545-481c-ec75-8d2ae27948a3"
      },
      "source": [
        "token_lens = []\n",
        "for txt in df.reviews:\n",
        "  tokens = tokenizer.encode(txt, max_length=512)\n",
        "  token_lens.append(len(tokens))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u4I3LggomnX0",
        "outputId": "c542bad2-227d-4304-a654-23ab13b45512"
      },
      "source": [
        "sns.distplot(token_lens)\n",
        "plt.xlim([0, 100]);\n",
        "plt.xlabel('Token count');"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WJrYUAKqnROb"
      },
      "source": [
        "MAX_LEN = 30"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z7g5E93Dnava"
      },
      "source": [
        "class ReviewDataset(Dataset):\n",
        "  def __init__(self, reviews, targets, tokenizer, max_len):\n",
        "    self.reviews = reviews\n",
        "    self.targets = targets\n",
        "    self.tokenizer = tokenizer\n",
        "    self.max_len = max_len\n",
        "  def __len__(self):\n",
        "    return len(self.reviews)\n",
        "  def __getitem__(self, item):\n",
        "    review = str(self.reviews[item])\n",
        "    target = self.targets[item]\n",
        "    encoding = self.tokenizer.encode_plus(\n",
        "      review,\n",
        "      add_special_tokens=True,\n",
        "      max_length=self.max_len,\n",
        "      return_token_type_ids=False,\n",
        "      pad_to_max_length=True,\n",
        "      return_attention_mask=True,\n",
        "      return_tensors='pt',\n",
        "    )\n",
        "    return {\n",
        "      'review_text': review,\n",
        "      'input_ids': encoding['input_ids'].flatten(),\n",
        "      'attention_mask': encoding['attention_mask'].flatten(),\n",
        "      'targets': torch.tensor(target, dtype=torch.long)\n",
        "    }"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "B7O6v8fAoL2Q",
        "outputId": "b6e10b91-41b9-4c89-da8f-1819ce0547a9"
      },
      "source": [
        "df_val = pd.read_csv(\"gold_test.csv\")\n",
        "df_val.drop(\"Unnamed: 0\",axis =1,inplace=True)\n",
        "df_val.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>reviews</th>\n",
              "      <th>ratings</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Doesn't work at ALL. Don't waste your money or...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>What crap.  Would need a lot more power to do ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Has no suction and didn't work. Not worth trying.</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>That is definitely a trash. Unable to clean an...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Didn't even worked on cleaning the ears at all...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                             reviews  ratings\n",
              "0  Doesn't work at ALL. Don't waste your money or...        1\n",
              "1  What crap.  Would need a lot more power to do ...        1\n",
              "2  Has no suction and didn't work. Not worth trying.        1\n",
              "3  That is definitely a trash. Unable to clean an...        1\n",
              "4  Didn't even worked on cleaning the ears at all...        1"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pmh0aJAcn49l"
      },
      "source": [
        "# df_train, df_test = train_test_split(\n",
        "#   df,\n",
        "#   test_size=0.1,\n",
        "#   random_state=RANDOM_SEED\n",
        "# )\n",
        "# df_val, df_test = train_test_split(\n",
        "#   df_test,\n",
        "#   test_size=0,\n",
        "#   random_state=RANDOM_SEED\n",
        "# )\n",
        "df_train = df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JMZx7J_T2ccH",
        "outputId": "eca1f669-f13c-4b94-d6ac-23ddc36f7ac5"
      },
      "source": [
        "df_train.shape, df_val.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((50000, 2), (10000, 2))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vG69ZFJZ2lHv"
      },
      "source": [
        "def create_data_loader(df, tokenizer, max_len, batch_size):\n",
        "  ds = ReviewDataset(\n",
        "    reviews=df.reviews.to_numpy(),\n",
        "    targets=df.ratings.to_numpy(),\n",
        "    tokenizer=tokenizer,\n",
        "    max_len=max_len\n",
        "  )\n",
        "  return DataLoader(\n",
        "    ds,\n",
        "    batch_size=batch_size,\n",
        "    num_workers=4\n",
        "  )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p6zppndH21yw"
      },
      "source": [
        "BATCH_SIZE = 16\n",
        "train_data_loader = create_data_loader(df_train, tokenizer, MAX_LEN, BATCH_SIZE)\n",
        "val_data_loader = create_data_loader(df_val, tokenizer, MAX_LEN, BATCH_SIZE)\n",
        "test_data_loader = create_data_loader(df_val, tokenizer, MAX_LEN, BATCH_SIZE)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wbcQ_WWq2-n4",
        "outputId": "142c878e-ab69-4a20-c613-e758535bb46c"
      },
      "source": [
        "data = next(iter(train_data_loader))\n",
        "data.keys()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict_keys(['review_text', 'input_ids', 'attention_mask', 'targets'])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1RPQ-G4M3PCd",
        "outputId": "f52300a3-a9f9-4320-f1f9-a92d546645cb"
      },
      "source": [
        "\n",
        "print(data['input_ids'].shape)\n",
        "print(data['input_ids'])\n",
        "print(data['attention_mask'].shape)\n",
        "print(data['targets'].shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([16, 30])\n",
            "tensor([[  101,  1188,  1520,  1108,  1304, 12862,  5838,   117,  4576,  1155,\n",
            "          5402,  1104,  1342,   119,   102,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
            "        [  101,   146,  1821,  1640,   170,  3866,  5442,  1105,  1450,   170,\n",
            "          2113,  1164,  1103, 13898,  8903,   117,  1133,   146,  3560,   170,\n",
            "          1974,  1167,  3455,  1142,  1520,   119,   102,     0,     0,     0],\n",
            "        [  101,   146,  1238,   112,   189,  1176,  1142,  3317,  1122,   188,\n",
            "         13601, 17363,  1155,  1223,  1139,  1257,  1194,  1193,  1103,  1285,\n",
            "           102,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
            "        [  101,   146,  2566,  1567,  1103,  3317,   119,   146,  8856,  5911,\n",
            "          4877,  1171,  4423,  1139,  1546,   102,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
            "        [  101,  1135,  2947,  1113,  1304,  3253,  1105,  2228,  1139,  1257,\n",
            "          1440, 19096,  1105,  9896,   102,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
            "        [  101, 16068,  1125,  1118,  1155,   119,  3497,  1480,  1198,  1400,\n",
            "          1618,   119, 19662,  1186,  1114,   170, 11079,   117,  1169,  1129,\n",
            "          1307,  1111,  4106,  1137,  4931, 12634,  1197,   119,   102,     0],\n",
            "        [  101,  1188, 17369, 26385, 24705,  9019,  1110,  1236,  6706,  1190,\n",
            "          1130,  1103,  3439,   117,  1134,  2502,  1107, 25997,  1165,   146,\n",
            "           112,   182,  3179,  1213,  1556,  1139, 17369, 26385,  1120,   102],\n",
            "        [  101,   146,  3306,  1142,  1111,  1139,  6508,  1105,  1119,  7284,\n",
            "          3097,  1122,  5438,  1111,   170,  1632,  3317,   102,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
            "        [  101, 15218,  3505,   117,  1218,  1189,   117,  2810,  1106,  1138,\n",
            "          1122,  1111,  1242,  1201,   119,   102,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
            "        [  101,  8835,  2484,   119,  2119, 13247,   119, 10860,  1116, 20015,\n",
            "          1105,  8415,  1304,  1218,   102,     0,     0,     0,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
            "        [  101,  1109,  8415,  1334,  1108,  1315,  1353,  1111,  1139,  8415,\n",
            "           119,  1252,   146,  5950,  1122,  1198,   170,  1376,  1105,  1122,\n",
            "         17976,  2503,  1208,   119,   102,     0,     0,     0,     0,     0],\n",
            "        [  101, 20375,  2058,   117,  1363,  4218,  1105,  3146,   119,  1109,\n",
            "         20015,  1334,  1198, 17976,  1139, 20015,   119,   102,     0,     0,\n",
            "             0,     0,     0,     0,     0,     0,     0,     0,     0,     0],\n",
            "        [  101, 20361,   119,  2038,  3945,   117,  4600,  1434,   117, 12890,\n",
            "         27861,  1193, 17117,  1105,  2426,  6691,   119,  1693,  1193,  6315,\n",
            "           106,   106,   106,   102,     0,     0,     0,     0,     0,     0],\n",
            "        [  101,  1135,  7634,  1139, 20015,  1105,   188, 22300,  8415,  1228,\n",
            "          1104,  1103,  4073,   119,  1109,  2484, 23363,  1536,  1115,  1122,\n",
            "          2762,   112,   189,  3253,  1499, 13229,  1166,  1137,  2873,   102],\n",
            "        [  101,  6424,  3505,   117,  1156, 18029,  1115,  1128,  4779,  1103,\n",
            "          3264,  1186,   188, 22300,  8415,   119,  1135, 17976,  3264,   117,\n",
            "          1139,  1385,  8415,  1225,  1136,   102,     0,     0,     0,     0],\n",
            "        [  101,  2896, 18886,  1204,  1902,   117,  1218, 21165,  1105,  4450,\n",
            "          8458,   119,  1135,   112,   188,  2712,  1536,  1106,  1817,  1149,\n",
            "          1113,   170,  5056,  3498,  1785,   119,  6424,  7229,   119,   102]])\n",
            "torch.Size([16, 30])\n",
            "torch.Size([16])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0B2Fv4g33ocW",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 115,
          "referenced_widgets": [
            "9f9d7c1b0a8a417b87313cfab89b3f0d",
            "35fb5a6893064a188bba3fb7d2e89e50",
            "40383165ceb94c9f9eea6974fc0cc770",
            "f2988eadc6ee495f902e460fd3627f4e",
            "a0acfb4eb3c943b892b4f1021a9f9434",
            "7a0ea911a24740ab94211d73c15de3ae",
            "e2a7d620398446f0881c165a74c13912",
            "1b33fa1ac00249548ebb8b2fc8261cbb",
            "ef23de20ad5144bb955a451047198bc3",
            "93cb34058a654bd581a2b213519a647a",
            "27ec57618b834fefaa7c3b30b472cae4",
            "793cd4450e124cb69ac2ca5458122d81",
            "c4ced2fbaf4c4db3a49b2333a0623e07",
            "0182f1e5800946b68e50b9bcb481c180",
            "bdf7558664324f5eb4a6c48cda4ab37e",
            "87be83eb523644d7bfe0c34592019966"
          ]
        },
        "outputId": "ee1714b7-eb52-4d88-f52a-05d081e8cf5e"
      },
      "source": [
        "PRE_TRAINED_MODEL_NAME = 'bert-base-cased'\n",
        "bert_model = BertModel.from_pretrained(PRE_TRAINED_MODEL_NAME, return_dict=False)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "9f9d7c1b0a8a417b87313cfab89b3f0d",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=570.0, style=ProgressStyle(description_…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "ef23de20ad5144bb955a451047198bc3",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=435779157.0, style=ProgressStyle(descri…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ovrauQoE3sBQ"
      },
      "source": [
        "class SentimentClassifier(nn.Module):\n",
        "  def __init__(self, n_classes):\n",
        "    super(SentimentClassifier, self).__init__()\n",
        "    self.bert = BertModel.from_pretrained(PRE_TRAINED_MODEL_NAME, return_dict=False)\n",
        "    self.drop = nn.Dropout(p=0.3)\n",
        "    self.out = nn.Linear(self.bert.config.hidden_size, n_classes)\n",
        "  def forward(self, input_ids, attention_mask):\n",
        "    _, pooled_output = self.bert(\n",
        "      input_ids=input_ids,\n",
        "      attention_mask=attention_mask\n",
        "    )\n",
        "    output = self.drop(pooled_output)\n",
        "    return self.out(output)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GBl6fU1V306-"
      },
      "source": [
        "model = SentimentClassifier(5)\n",
        "model = model.to(device)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lZiIltYb35GZ",
        "outputId": "ab1c6848-c8fd-4ebd-ba90-db7195df8289"
      },
      "source": [
        "input_ids = data['input_ids'].to(device)\n",
        "attention_mask = data['attention_mask'].to(device)\n",
        "# input_ids = data['input_ids']\n",
        "# attention_mask = data['attention_mask']\n",
        "print(input_ids.shape) # batch size x seq length\n",
        "print(attention_mask.shape) # batch size x seq lengt"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([16, 30])\n",
            "torch.Size([16, 30])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pki-8zYr4Mbl",
        "outputId": "81c874bb-8e96-44ec-eb3e-62c54797e37b"
      },
      "source": [
        "nn.functional.softmax(model(input_ids, attention_mask), dim=1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.3737, 0.1020, 0.1437, 0.1655, 0.2152],\n",
              "        [0.2507, 0.1470, 0.3078, 0.1636, 0.1309],\n",
              "        [0.3472, 0.1287, 0.2091, 0.1451, 0.1698],\n",
              "        [0.2630, 0.0993, 0.2177, 0.1455, 0.2745],\n",
              "        [0.3150, 0.1328, 0.2112, 0.1102, 0.2308],\n",
              "        [0.2385, 0.1490, 0.3035, 0.1091, 0.1999],\n",
              "        [0.3430, 0.0624, 0.2315, 0.1332, 0.2299],\n",
              "        [0.2715, 0.0884, 0.3787, 0.1064, 0.1550],\n",
              "        [0.2597, 0.1516, 0.1831, 0.1339, 0.2716],\n",
              "        [0.2413, 0.0835, 0.2885, 0.0783, 0.3083],\n",
              "        [0.3221, 0.1399, 0.1854, 0.0779, 0.2746],\n",
              "        [0.2064, 0.1803, 0.2887, 0.1603, 0.1642],\n",
              "        [0.1241, 0.0860, 0.4071, 0.0712, 0.3116],\n",
              "        [0.2510, 0.0613, 0.3754, 0.0878, 0.2245],\n",
              "        [0.2030, 0.1156, 0.3995, 0.0841, 0.1979],\n",
              "        [0.3753, 0.1171, 0.2071, 0.0898, 0.2108]], grad_fn=<SoftmaxBackward>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hpZTG5id4Qqu"
      },
      "source": [
        "EPOCHS = 10\n",
        "optimizer = AdamW(model.parameters(), lr=2e-5, correct_bias=False)\n",
        "total_steps = len(train_data_loader) * EPOCHS\n",
        "scheduler = get_linear_schedule_with_warmup(\n",
        "  optimizer,\n",
        "  num_warmup_steps=0,\n",
        "  num_training_steps=total_steps\n",
        ")\n",
        "loss_fn = nn.CrossEntropyLoss().to(device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3AOq1dat7ClW"
      },
      "source": [
        "def train_epoch(\n",
        "  model,\n",
        "  data_loader,\n",
        "  loss_fn,\n",
        "  optimizer,\n",
        "  device,\n",
        "  scheduler,\n",
        "  n_examples\n",
        "):\n",
        "  model = model.train()\n",
        "  losses = []\n",
        "  correct_predictions = 0\n",
        "  for d in data_loader:\n",
        "    input_ids = d[\"input_ids\"].to(device)\n",
        "    attention_mask = d[\"attention_mask\"].to(device)\n",
        "    targets = d[\"targets\"] - 1 \n",
        "    targets = targets.to(device)\n",
        "    # input_ids = d[\"input_ids\"]\n",
        "    # attention_mask = d[\"attention_mask\"]\n",
        "    # targets = d[\"targets\"] - 1 \n",
        "    outputs = model(\n",
        "      input_ids=input_ids,\n",
        "      attention_mask=attention_mask\n",
        "    )\n",
        "    _, preds = torch.max(outputs, dim=1)\n",
        "    # print(preds)\n",
        "    # print(outputs)\n",
        "    # print(targets)\n",
        "    loss = loss_fn(outputs, targets)\n",
        "    correct_predictions += torch.sum(preds == targets)\n",
        "    losses.append(loss.item())\n",
        "    loss.backward()\n",
        "    nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
        "    optimizer.step()\n",
        "    scheduler.step()\n",
        "    optimizer.zero_grad()\n",
        "  return correct_predictions.double() / n_examples, np.mean(losses)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ESkrAJ4_7I_T"
      },
      "source": [
        "def eval_model(model, data_loader, loss_fn, device, n_examples):\n",
        "  model = model.eval()\n",
        "  losses = []\n",
        "  correct_predictions = 0\n",
        "  with torch.no_grad():\n",
        "    for d in data_loader:\n",
        "      input_ids = d[\"input_ids\"].to(device)\n",
        "      attention_mask = d[\"attention_mask\"].to(device)\n",
        "      targets = d[\"targets\"] - 1 \n",
        "      targets = targets.to(device)\n",
        "    #   input_ids = d[\"input_ids\"]\n",
        "    #   attention_mask = d[\"attention_mask\"]\n",
        "    #   targets = d[\"targets\"] - 1 \n",
        "      outputs = model(\n",
        "        input_ids=input_ids,\n",
        "        attention_mask=attention_mask\n",
        "      )\n",
        "      _, preds = torch.max(outputs, dim=1)\n",
        "    #   print(preds)\n",
        "    #   print(outputs)\n",
        "    #   print(targets)\n",
        "      loss = loss_fn(outputs, targets)\n",
        "      correct_predictions += torch.sum(preds == targets)\n",
        "      losses.append(loss.item())\n",
        "  return correct_predictions.double() / n_examples, np.mean(losses)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GaspG74wA45e"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 459
        },
        "id": "lZVrAm8y7OMi",
        "outputId": "eed89af6-2c84-464c-c465-34382ec2a8e5"
      },
      "source": [
        "%%time\n",
        "history = defaultdict(list)\n",
        "best_accuracy = 0\n",
        "for epoch in range(EPOCHS):\n",
        "  print(f'Epoch {epoch + 1}/{EPOCHS}')\n",
        "  print('-' * 10)\n",
        "  train_acc, train_loss = train_epoch(\n",
        "    model,\n",
        "    train_data_loader,\n",
        "    loss_fn,\n",
        "    optimizer,\n",
        "    device,\n",
        "    scheduler,\n",
        "    len(df_train)\n",
        "  )\n",
        "  print(f'Train loss {train_loss} accuracy {train_acc}')\n",
        "  val_acc, val_loss = eval_model(\n",
        "    model,\n",
        "    val_data_loader,\n",
        "    loss_fn,\n",
        "    device,\n",
        "    len(df_val)\n",
        "  )\n",
        "  print(f'Val   loss {val_loss} accuracy {val_acc}')\n",
        "  print()\n",
        "  history['train_acc'].append(train_acc)\n",
        "  history['train_loss'].append(train_loss)\n",
        "  history['val_acc'].append(val_acc)\n",
        "  history['val_loss'].append(val_loss)\n",
        "  if val_acc > best_accuracy:\n",
        "    torch.save(model.state_dict(), 'best_model_state.bin')\n",
        "    best_accuracy = val_acc"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "----------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-35-e4375c7046a6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_cell_magic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'time'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"history = defaultdict(list)\\nbest_accuracy = 0\\nfor epoch in range(EPOCHS):\\n  print(f'Epoch {epoch + 1}/{EPOCHS}')\\n  print('-' * 10)\\n  train_acc, train_loss = train_epoch(\\n    model,\\n    train_data_loader,\\n    loss_fn,\\n    optimizer,\\n    device,\\n    scheduler,\\n    len(df_train)\\n  )\\n  print(f'Train loss {train_loss} accuracy {train_acc}')\\n  val_acc, val_loss = eval_model(\\n    model,\\n    val_data_loader,\\n    loss_fn,\\n    device,\\n    len(df_val)\\n  )\\n  print(f'Val   loss {val_loss} accuracy {val_acc}')\\n  print()\\n  history['train_acc'].append(train_acc)\\n  history['train_loss'].append(train_loss)\\n  history['val_acc'].append(val_acc)\\n  history['val_loss'].append(val_loss)\\n  if val_acc > best_accuracy:\\n    torch.save(model.state_dict(), 'best_model_state.bin')\\n    best_accuracy = val_acc\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mrun_cell_magic\u001b[0;34m(self, magic_name, line, cell)\u001b[0m\n\u001b[1;32m   2115\u001b[0m             \u001b[0mmagic_arg_s\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvar_expand\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstack_depth\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2116\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuiltin_trap\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2117\u001b[0;31m                 \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmagic_arg_s\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcell\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2118\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2119\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<decorator-gen-53>\u001b[0m in \u001b[0;36mtime\u001b[0;34m(self, line, cell, local_ns)\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/IPython/core/magic.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(f, *a, **k)\u001b[0m\n\u001b[1;32m    186\u001b[0m     \u001b[0;31m# but it's overkill for just that one bit of state.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mmagic_deco\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 188\u001b[0;31m         \u001b[0mcall\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    189\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    190\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/IPython/core/magics/execution.py\u001b[0m in \u001b[0;36mtime\u001b[0;34m(self, line, cell, local_ns)\u001b[0m\n\u001b[1;32m   1191\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1192\u001b[0m             \u001b[0mst\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclock2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1193\u001b[0;31m             \u001b[0mexec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mglob\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlocal_ns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1194\u001b[0m             \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclock2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1195\u001b[0m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m<ipython-input-31-ba14897e4218>\u001b[0m in \u001b[0;36mtrain_epoch\u001b[0;34m(model, data_loader, loss_fn, optimizer, device, scheduler, n_examples)\u001b[0m\n\u001b[1;32m     21\u001b[0m     outputs = model(\n\u001b[1;32m     22\u001b[0m       \u001b[0minput_ids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m       \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattention_mask\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m     )\n\u001b[1;32m     25\u001b[0m     \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpreds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-26-2bd68068d8e8>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask)\u001b[0m\n\u001b[1;32m      8\u001b[0m     _, pooled_output = self.bert(\n\u001b[1;32m      9\u001b[0m       \u001b[0minput_ids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m       \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattention_mask\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m     )\n\u001b[1;32m     12\u001b[0m     \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpooled_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    979\u001b[0m             \u001b[0moutput_attentions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_attentions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    980\u001b[0m             \u001b[0moutput_hidden_states\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_hidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 981\u001b[0;31m             \u001b[0mreturn_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreturn_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    982\u001b[0m         )\n\u001b[1;32m    983\u001b[0m         \u001b[0msequence_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mencoder_outputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    573\u001b[0m                     \u001b[0mencoder_attention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    574\u001b[0m                     \u001b[0mpast_key_value\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 575\u001b[0;31m                     \u001b[0moutput_attentions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    576\u001b[0m                 )\n\u001b[1;32m    577\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[1;32m    495\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    496\u001b[0m         layer_output = apply_chunking_to_forward(\n\u001b[0;32m--> 497\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeed_forward_chunk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchunk_size_feed_forward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseq_len_dim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_output\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    498\u001b[0m         )\n\u001b[1;32m    499\u001b[0m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlayer_output\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/modeling_utils.py\u001b[0m in \u001b[0;36mapply_chunking_to_forward\u001b[0;34m(forward_fn, chunk_size, chunk_dim, *input_tensors)\u001b[0m\n\u001b[1;32m   1815\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_chunks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mchunk_dim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1816\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1817\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mforward_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput_tensors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mfeed_forward_chunk\u001b[0;34m(self, attention_output)\u001b[0m\n\u001b[1;32m    507\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfeed_forward_chunk\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    508\u001b[0m         \u001b[0mintermediate_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mintermediate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mattention_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 509\u001b[0;31m         \u001b[0mlayer_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mintermediate_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    510\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mlayer_output\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    511\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, input_tensor)\u001b[0m\n\u001b[1;32m    422\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    423\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 424\u001b[0;31m         \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    425\u001b[0m         \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    426\u001b[0m         \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLayerNorm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0minput_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     92\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 94\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     95\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mlinear\u001b[0;34m(input, weight, bias)\u001b[0m\n\u001b[1;32m   1751\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhas_torch_function_variadic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1752\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mhandle_torch_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1753\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1754\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1755\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GVqluczN7Ujx"
      },
      "source": [
        "plt.plot(history['train_acc'], label='train accuracy')\n",
        "plt.plot(history['val_acc'], label='validation accuracy')\n",
        "plt.title('Training history')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend()\n",
        "plt.ylim([0, 1])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7XI75RpFvhZk",
        "outputId": "e389e85f-180c-4a5e-d040-503550e8c7cb"
      },
      "source": [
        "model.load_state_dict(torch.load('best_model_state.bin'), strict=False)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yr4_-Io1ZHuB",
        "outputId": "cdc45a61-8268-4529-a628-e28f3d10c47d"
      },
      "source": [
        "test_acc, _ = eval_model(\n",
        "  model,\n",
        "  val_data_loader,\n",
        "  loss_fn,\n",
        "  device,\n",
        "  len(df_val)\n",
        ")\n",
        "test_acc.item()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2079: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2079: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2079: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2079: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.7373000000000001"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oERJOYO9ZHxK"
      },
      "source": [
        "def get_predictions(model, data_loader):\n",
        "  model = model.eval()\n",
        "  review_texts = []\n",
        "  predictions = []\n",
        "  prediction_probs = []\n",
        "  real_values = []\n",
        "  with torch.no_grad():\n",
        "    for d in data_loader:\n",
        "      texts = d[\"review_text\"]\n",
        "      input_ids = d[\"input_ids\"].to(device)\n",
        "      attention_mask = d[\"attention_mask\"].to(device)\n",
        "      targets = d[\"targets\"] - 1 \n",
        "      targets = d[\"targets\"].to(device)\n",
        "      outputs = model(\n",
        "        input_ids=input_ids,\n",
        "        attention_mask=attention_mask\n",
        "      )\n",
        "      _, preds = torch.max(outputs, dim=1)\n",
        "      review_texts.extend(texts)\n",
        "      predictions.extend(preds)\n",
        "      prediction_probs.extend(outputs)\n",
        "      real_values.extend(targets)\n",
        "  predictions = torch.stack(predictions).cpu()\n",
        "  prediction_probs = torch.stack(prediction_probs).cpu()\n",
        "  real_values = torch.stack(real_values).cpu()\n",
        "  return review_texts, predictions + 1, prediction_probs, real_values"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s-0nzSaUZH0A",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "660a245a-7a41-4157-e954-50d6a4d8ac60"
      },
      "source": [
        "y_review_texts, y_pred, y_pred_probs, y_test = get_predictions(\n",
        "  model,\n",
        "  val_data_loader\n",
        ")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yAChvSCWZpvr",
        "outputId": "d3364cf3-eb23-47d8-cc00-95f176dc5c7a"
      },
      "source": [
        "print(classification_report(y_test, y_pred))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       0.68      0.80      0.73      1271\n",
            "           2       0.39      0.13      0.19       630\n",
            "           3       0.41      0.45      0.43       911\n",
            "           4       0.45      0.28      0.35      1404\n",
            "           5       0.85      0.95      0.90      5784\n",
            "\n",
            "    accuracy                           0.74     10000\n",
            "   macro avg       0.56      0.52      0.52     10000\n",
            "weighted avg       0.70      0.74      0.71     10000\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 281
        },
        "id": "7LxfUardZpzR",
        "outputId": "50643d42-332f-4db8-afa6-e96fc7aba273"
      },
      "source": [
        "def show_confusion_matrix(confusion_matrix):\n",
        "  hmap = sns.heatmap(confusion_matrix, annot=True, fmt=\"d\", cmap=\"Blues\")\n",
        "  hmap.yaxis.set_ticklabels(hmap.yaxis.get_ticklabels(), rotation=0, ha='right')\n",
        "  hmap.xaxis.set_ticklabels(hmap.xaxis.get_ticklabels(), rotation=30, ha='right')\n",
        "  plt.ylabel('True sentiment')\n",
        "  plt.xlabel('Predicted sentiment');\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "df_cm = pd.DataFrame(cm, index=[str(i) for i in range(1,6)], columns=[str(i) for i in range(1,6)])\n",
        "show_confusion_matrix(df_cm)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5CFzYQTVYGte",
        "outputId": "458d3c03-4774-4ad9-e807-ad6ea623ae9a"
      },
      "source": [
        "! pip install lime"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting lime\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f5/86/91a13127d83d793ecb50eb75e716f76e6eda809b6803c5a4ff462339789e/lime-0.2.0.1.tar.gz (275kB)\n",
            "\r\u001b[K     |█▏                              | 10kB 24.9MB/s eta 0:00:01\r\u001b[K     |██▍                             | 20kB 14.0MB/s eta 0:00:01\r\u001b[K     |███▋                            | 30kB 12.6MB/s eta 0:00:01\r\u001b[K     |████▊                           | 40kB 11.9MB/s eta 0:00:01\r\u001b[K     |██████                          | 51kB 7.9MB/s eta 0:00:01\r\u001b[K     |███████▏                        | 61kB 8.1MB/s eta 0:00:01\r\u001b[K     |████████▎                       | 71kB 8.6MB/s eta 0:00:01\r\u001b[K     |█████████▌                      | 81kB 9.4MB/s eta 0:00:01\r\u001b[K     |██████████▊                     | 92kB 8.6MB/s eta 0:00:01\r\u001b[K     |███████████▉                    | 102kB 7.7MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 112kB 7.7MB/s eta 0:00:01\r\u001b[K     |██████████████▎                 | 122kB 7.7MB/s eta 0:00:01\r\u001b[K     |███████████████▌                | 133kB 7.7MB/s eta 0:00:01\r\u001b[K     |████████████████▋               | 143kB 7.7MB/s eta 0:00:01\r\u001b[K     |█████████████████▉              | 153kB 7.7MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 163kB 7.7MB/s eta 0:00:01\r\u001b[K     |████████████████████▏           | 174kB 7.7MB/s eta 0:00:01\r\u001b[K     |█████████████████████▍          | 184kB 7.7MB/s eta 0:00:01\r\u001b[K     |██████████████████████▋         | 194kB 7.7MB/s eta 0:00:01\r\u001b[K     |███████████████████████▊        | 204kB 7.7MB/s eta 0:00:01\r\u001b[K     |█████████████████████████       | 215kB 7.7MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▏     | 225kB 7.7MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▍    | 235kB 7.7MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▌   | 245kB 7.7MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▊  | 256kB 7.7MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████ | 266kB 7.7MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 276kB 7.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from lime) (3.2.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from lime) (1.19.5)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from lime) (1.4.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from lime) (4.41.1)\n",
            "Requirement already satisfied: scikit-learn>=0.18 in /usr/local/lib/python3.7/dist-packages (from lime) (0.22.2.post1)\n",
            "Requirement already satisfied: scikit-image>=0.12 in /usr/local/lib/python3.7/dist-packages (from lime) (0.16.2)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->lime) (2.4.7)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->lime) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->lime) (0.10.0)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->lime) (2.8.1)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.18->lime) (1.0.1)\n",
            "Requirement already satisfied: imageio>=2.3.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image>=0.12->lime) (2.4.1)\n",
            "Requirement already satisfied: pillow>=4.3.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image>=0.12->lime) (7.1.2)\n",
            "Requirement already satisfied: PyWavelets>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image>=0.12->lime) (1.1.1)\n",
            "Requirement already satisfied: networkx>=2.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image>=0.12->lime) (2.5.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from cycler>=0.10->matplotlib->lime) (1.15.0)\n",
            "Requirement already satisfied: decorator<5,>=4.3 in /usr/local/lib/python3.7/dist-packages (from networkx>=2.0->scikit-image>=0.12->lime) (4.4.2)\n",
            "Building wheels for collected packages: lime\n",
            "  Building wheel for lime (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for lime: filename=lime-0.2.0.1-cp37-none-any.whl size=283846 sha256=3632f72ec035c97e47bfc4f9e809c845511a311b9eaeb6291e694d9e252ab141\n",
            "  Stored in directory: /root/.cache/pip/wheels/4c/4f/a5/0bc765457bd41378bf3ce8d17d7495369d6e7ca3b712c60c89\n",
            "Successfully built lime\n",
            "Installing collected packages: lime\n",
            "Successfully installed lime-0.2.0.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2rsYe3eS7jlO"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ukWxntum7j1w"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 388
        },
        "id": "vogpctwRDiBB",
        "outputId": "8e61a9ff-4459-438a-840d-22c3cb4e5a1b"
      },
      "source": [
        "import torch.nn.functional as F\n",
        "from lime.lime_text import LimeTextExplainer\n",
        "import torch\n",
        "torch.cuda.empty_cache()\n",
        "\n",
        "model1 = SentimentClassifier(5)\n",
        "model1 = model1.to(device)\n",
        "model1.load_state_dict(torch.load('best_model_state.bin'), strict=False)\n",
        "tokenizer1 = BertTokenizer.from_pretrained('bert-base-cased')\n",
        "class_names = ['1','2', '3','4','5']\n",
        "\n",
        "def predictor(texts):\n",
        "    ay = []\n",
        "    for text in texts:\n",
        "      encoded_review = tokenizer1.encode_plus(\n",
        "      texts,\n",
        "      max_length=MAX_LEN,\n",
        "      add_special_tokens=True,\n",
        "      return_token_type_ids=False,\n",
        "      pad_to_max_length=True,\n",
        "      return_attention_mask=True,\n",
        "      return_tensors='pt',\n",
        "      )\n",
        "      \n",
        "      input_ids = encoded_review['input_ids'].to(device)\n",
        "      attention_mask = encoded_review['attention_mask'].to(device)\n",
        "      output = model1(input_ids, attention_mask)\n",
        "      output = F.softmax(output)\n",
        "      _, prediction = torch.max(output, dim=1)\n",
        "      # print(prediction)\n",
        "      ay.extend(output)\n",
        "      \n",
        "      # print(output)\n",
        "      \n",
        "    predictions = torch.stack(ay).cpu().detach().numpy()\n",
        "    return predictions\n",
        "\n",
        "def predict_prob(sent):\n",
        "    if isinstance(sent,list):\n",
        "        out = predictor(sent)\n",
        "        return(out)\n",
        "    elif isinstance(sent,str):\n",
        "        out = predictor([sent])\n",
        "        print('out',out)\n",
        "        return(out)\n",
        "    else:\n",
        "        return(\"Some ERRORRRR\")\n",
        "\n",
        "explainer = LimeTextExplainer(class_names=class_names)\n",
        "\n",
        "str_to_predict = \"surprising increase in revenue in spite of decrease in market share\"\n",
        "exp = explainer.explain_instance(str_to_predict, predict_prob,num_features=30)\n",
        "exp.show_in_notebook(text=str_to_predict)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-68-cf9be45fbfb3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mmodel1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSentimentClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mmodel1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0mmodel1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'best_model_state.bin'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstrict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mtokenizer1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBertTokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'bert-base-cased'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mto\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    671\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_floating_point\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_complex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_blocking\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    672\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 673\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    674\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    675\u001b[0m     def register_backward_hook(\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    385\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    386\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 387\u001b[0;31m             \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    388\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    389\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    385\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    386\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 387\u001b[0;31m             \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    388\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    389\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    385\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    386\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 387\u001b[0;31m             \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    388\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    389\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    407\u001b[0m                 \u001b[0;31m# `with torch.no_grad():`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    408\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 409\u001b[0;31m                     \u001b[0mparam_applied\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    410\u001b[0m                 \u001b[0mshould_use_set_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    411\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mshould_use_set_data\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mconvert\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m    669\u001b[0m                 return t.to(device, dtype if t.is_floating_point() or t.is_complex() else None,\n\u001b[1;32m    670\u001b[0m                             non_blocking, memory_format=convert_to_format)\n\u001b[0;32m--> 671\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_floating_point\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_complex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_blocking\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    672\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    673\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: CUDA out of memory. Tried to allocate 86.00 MiB (GPU 0; 14.76 GiB total capacity; 13.48 GiB already allocated; 3.75 MiB free; 13.72 GiB reserved in total by PyTorch)"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EqKBit1ZBBg3"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1qGfM21vyHcl"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2uIlJ_W_YJJh"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2YhERnePYex8"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}